{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_Interp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoeksq2rDH8x"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_dir = '../input/asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = '../input/asl_alphabet_test/asl_alphabet_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMrQ4bErEHsL"
      },
      "source": [
        "img_size = 64 \n",
        "\n",
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}\n",
        "\n",
        "# directory should be the path to the folder with the images, use the predefined variables 'train' and 'evaluation'\n",
        "# The size is for resizing the images.  All images are squares.  The reason we decided to implement this size variable is because\n",
        "# we found multiple different proposed solutions using image sizes ranging from 64 to 580, with such a large range we wanted room to \n",
        "# adjust later in the process.\n",
        "def load_data():\n",
        "    print(\"loading images\")\n",
        "    images = []\n",
        "    labels = []\n",
        "    # size = 64,64\n",
        "    # print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        # print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            images.append(img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    \n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    \n",
        "    labels = keras.utils.to_categorical(labels)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "images, labels = load_data()\n",
        "\n",
        "# Here we are going to use scikit to split our training data into two separate pieces, training and testing (note testing is separate from evaluation)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.1)\n",
        "\n",
        "# This is to load our evaluation data for the final deliverable\n",
        "# if labels_set == sorted(os.listdir(evaluation)):\n",
        "#     x_eval, y_eval = load_images(directory = evaluation, size = img_size)\n",
        "\n",
        "print('Loaded', len(X_train),'images for training,')\n",
        "print('Loaded', len(X_test),'images for testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXyLEo2pEyav"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    kernel = [3,3]\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(16, kernel_size = kernel, padding = 'same', activation = 'relu', input_shape = (64,64,3)))\n",
        "    model.add(Conv2D(32, kernel_size = kernel, padding = 'same', activation = 'relu'))\n",
        "    model.add(MaxPool2D(pool_size = kernel))\n",
        "    \n",
        "    model.add(Conv2D(32, kernel_size = kernel, padding = 'same', activation = 'relu'))\n",
        "    model.add(Conv2D(64, kernel_size = kernel, padding = 'same', activation = 'relu'))\n",
        "    model.add(MaxPool2D(pool_size = kernel))\n",
        "    \n",
        "    model.add(Conv2D(128, kernel_size = kernel, padding = 'same', activation = 'relu'))\n",
        "    model.add(Conv2D(256, kernel_size = kernel, padding = 'same', activation = 'relu'))\n",
        "    model.add(MaxPool2D(pool_size = kernel))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
        "    model.add(Dense(29, activation = 'softmax'))\n",
        "    \n",
        "    model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n",
        "    \n",
        "    print(\"MODEL CREATED\")\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def fit_model():\n",
        "    model_hist = model.fit(X_train, Y_train, batch_size = 64, epochs = 5, validation_split = 0.1)\n",
        "    return model_hist \n",
        "\n",
        "model = create_model()\n",
        "curr_model_hist = fit_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iondHHLVE4dT"
      },
      "source": [
        "plt.plot(curr_model_hist.history['acc'])\n",
        "plt.plot(curr_model_hist.history['val_acc'])\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.title('accuracy plot - train vs test')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(curr_model_hist.history['loss'])\n",
        "plt.plot(curr_model_hist.history['val_loss'])\n",
        "plt.legend(['training loss', 'validation loss'], loc = 'upper right')\n",
        "plt.title('loss plot - training vs vaidation')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "evaluate_metrics = model.evaluate(X_test, Y_test)\n",
        "print(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZU5PGNQFBnw"
      },
      "source": [
        "def load_test_data():\n",
        "    images = []\n",
        "    names = []\n",
        "    # size = 64,64\n",
        "    for image in os.listdir(test_dir):\n",
        "        temp = cv2.imread(test_dir + '/' + image)\n",
        "        temp = cv2.resize(temp, (img_size, img_size))\n",
        "        images.append(temp)\n",
        "        names.append(image)\n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    return images, names\n",
        "\n",
        "def get_labels_for_plot(predictions):\n",
        "    predictions_labels = []\n",
        "    for i in range(len(predictions)):\n",
        "        for ins in labels_dict:\n",
        "            if predictions[i] == labels_dict[ins]:\n",
        "                predictions_labels.append(ins)\n",
        "                break\n",
        "    return predictions_labels\n",
        "\n",
        "predictions_labels_plot = get_labels_for_plot(predictions)\n",
        "\n",
        "test_images, test_img_names = load_test_data()\n",
        "\n",
        "# make predictions on an image and append it to the list (predictions).\n",
        "predictions = [model.predict_classes(image.reshape(1,64,64,3))[0] for image in test_images]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGbmxIjEFNGd"
      },
      "source": [
        "predfigure = plt.figure(figsize = (13,13))\n",
        "def plot_image_1(fig, image, label, prediction, predictions_label, row, col, index):\n",
        "    fig.add_subplot(row, col, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\" + label\n",
        "    plt.title(title)\n",
        "    return\n",
        "\n",
        "image_index = 0\n",
        "row = 5\n",
        "col = 6\n",
        "for i in range(1,(row*col-1)):\n",
        "    plot_image_1(predfigure, test_images[image_index], test_img_names[image_index], predictions[image_index], predictions_labels_plot[image_index], row, col, i)\n",
        "    image_index = image_index + 1\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnR-SUVaFOn_"
      },
      "source": [
        "model.save('asl_predictor.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}